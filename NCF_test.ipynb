{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make function and build model\n",
    "\n",
    "We make functions to do data process, select optimizer and so on. Meanwhile, building NCF model for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Mn7chlhl8lmi"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "random.seed(0)\n",
    "\n",
    "class DataProcess(object):\n",
    "    def __init__(self, filename):\n",
    "        self._filename = filename\n",
    "        self._loadData()\n",
    "        self._preProcess()\n",
    "        self._binarize(self._originalRatings)\n",
    "        # 对'userId'这一列的数据，先去重，然后构成一个用户列表\n",
    "        self._userPool = set(self._originalRatings['userId'].unique())\n",
    "        self._itemPool = set(self._originalRatings['itemId'].unique())\n",
    "        \n",
    "#         print(\"user_pool size: \", len(self._userPool))\n",
    "#         print(\"item_pool size: \", len(self._itemPool))\n",
    "\n",
    "        self._select_Negatives(self._originalRatings)\n",
    "        self._split_pool(self._preprocessRatings)\n",
    "\n",
    "    def _loadData(self):\n",
    "        self._originalRatings = pd.read_csv(self._filename, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'],\n",
    "                                            engine='python')\n",
    "        return self._originalRatings\n",
    "\n",
    "    def _preProcess(self):\n",
    "        \"\"\"\n",
    "        对user和item都重新编号，这里这么做的原因是因为，模型的输入是one-hot向量，需要把user和item都限制在Embedding的长度之内，\n",
    "        模型的两个输入的长度分别是user和item的数量，所以要重新从0编号。\n",
    "        \"\"\"\n",
    "        # 1. 新建名为\"userId\"的列，这列对用户从0开始编号\n",
    "        user_id = self._originalRatings[['uid']].drop_duplicates().reindex()\n",
    "        user_id['userId'] = np.arange(len(user_id)) #根据user的长度创建一个数组\n",
    "        # 将原先的DataFrame与user_id按照\"uid\"这一列进行合并\n",
    "        self._originalRatings = pd.merge(self._originalRatings, user_id, on=['uid'], how='left')\n",
    "\n",
    "        # 2. 对物品进行重新排列\n",
    "        item_id = self._originalRatings[['mid']].drop_duplicates()\n",
    "        item_id['itemId'] = np.arange(len(item_id))\n",
    "        self._originalRatings = pd.merge(self._originalRatings, item_id, on=['mid'], how='left')\n",
    "\n",
    "        # 按照['userId', 'itemId', 'rating', 'timestamp']的顺序重新排列\n",
    "        self._originalRatings = self._originalRatings[['userId', 'itemId', 'rating', 'timestamp']]\n",
    "        \n",
    "#         print(self._originalRatings)\n",
    "        \n",
    "#         print('Range of userId is [{}, {}]'.format(self._originalRatings.userId.min(), self._originalRatings.userId.max()))\n",
    "#         print('Range of itemId is [{}, {}]'.format(self._originalRatings.itemId.min(), self._originalRatings.itemId.max()))\n",
    "\n",
    "    def _binarize(self, ratings):\n",
    "        \"\"\"\n",
    "        binarize data into 0 or 1 for implicit feedback\n",
    "        \"\"\"\n",
    "        ratings = deepcopy(ratings)\n",
    "        ratings['rating'][ratings['rating'] > 0] = 1.0\n",
    "        self._preprocessRatings = ratings\n",
    "        # print(\"binary: \\n\", self._preprocessRatings)\n",
    "\n",
    "    def _select_Negatives(self, ratings):\n",
    "        \"\"\"\n",
    "        Select al;l negative samples and 100 sampled negative items for each user.\n",
    "        \"\"\"\n",
    "        # 构造user-item表\n",
    "        interact_status = ratings.groupby('userId')['itemId'].apply(set).reset_index().rename(\n",
    "            columns={'itemId': 'interacted_items'})\n",
    "        \n",
    "#         print(\"interact_status: \\n\", interact_status)\n",
    "\n",
    "        # 把与用户没有产生过交互的样本都当做是负样本\n",
    "        interact_status['negative_items'] = interact_status['interacted_items'].apply(lambda x: self._itemPool - x)\n",
    "\n",
    "        # 从上面的全部负样本中随机选99个出来\n",
    "        interact_status['negative_samples'] = interact_status['negative_items'].apply(lambda x: random.sample(x, 99))\n",
    "        \n",
    "#         print(\"after sampling interact_status: \\n\", interact_status)\n",
    "\n",
    "#         print(\"select and rearrange columns\")\n",
    "\n",
    "        self._negatives = interact_status[['userId', 'negative_items', 'negative_samples']]\n",
    "\n",
    "    def _split_pool(self, ratings):\n",
    "        \"\"\"leave one out train/test split \"\"\"\n",
    "        \n",
    "#         print(\"sort by timestamp descend\")\n",
    "\n",
    "        # 先按照'userID'进行分组，然后根据时间戳降序排列\n",
    "        ratings['rank_latest'] = ratings.groupby(['userId'])['timestamp'].rank(method='first', ascending=False)\n",
    "        \n",
    "#         print(ratings)\n",
    "\n",
    "        # 选取排名第一的数据作为测试集，也就是最新的那个数据\n",
    "        test = ratings[ratings['rank_latest'] == 1]\n",
    "        # 选取所有排名靠后的，也就是历史数据当做训练集\n",
    "        train = ratings[ratings['rank_latest'] > 1]\n",
    "        # print(\"test: \\n\", test)\n",
    "        # print(\"train: \\n\", train)\n",
    "\n",
    "#         print(\"size of test {0}, size of train {1}\".format(len(test), len(train)))\n",
    "\n",
    "        # 确保训练集和测试集的userId是一样的\n",
    "        assert train['userId'].nunique() == test['userId'].nunique()\n",
    "\n",
    "        self.train_ratings = train[['userId', 'itemId', 'rating']]\n",
    "        self.test_ratings = test[['userId', 'itemId', 'rating']]\n",
    "\n",
    "    def sample_generator(self, num_negatives):\n",
    "        # 合并之后的train_ratings的列包括['userId','itemId'，'rating','negative_items']\n",
    "        train_ratings = pd.merge(self.train_ratings, self._negatives[['userId', 'negative_items']], on='userId')\n",
    "        # 从用户的全部负样本集合中随机选择num_negatives个样本当做负样本，并产生一个新的名为\"negatives\"的列\n",
    "        train_ratings['negatives'] = train_ratings['negative_items'].apply(lambda x: random.sample(x, num_negatives))\n",
    "        \n",
    "#         print(train_ratings)\n",
    "\n",
    "        # 构造模型所需要的数据，分别是输入user、items以及目标分值ratings。\n",
    "        users, items, ratings = [], [], []\n",
    "        for row in train_ratings.itertuples():\n",
    "            # 构造正样本，分别是userId， itemId以及目标分值1\n",
    "            users.append(int(row.userId))\n",
    "            items.append(int(row.itemId))\n",
    "            ratings.append(float(row.rating))\n",
    "            # 为每个用户构造num_negatives个负样本，分别是userId， itemId以及目标分值0\n",
    "            for i in range(num_negatives):\n",
    "                users.append(int(row.userId))\n",
    "                items.append(int(row.negatives[i]))\n",
    "                ratings.append(float(0)) # 负样本的ratings为0，直接强行设置为0\n",
    "\n",
    "        return users, items, ratings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XUIgx1qJAn3E"
   },
   "outputs": [],
   "source": [
    "class NCF(object):\n",
    "    def __init__(self, config, latent_dim_gmf=8, latent_dim_mlp=8):\n",
    "        self._config = config\n",
    "        self._num_users = config['num_users']\n",
    "        self._num_items = config['num_items']\n",
    "        self._latent_dim_gmf = latent_dim_gmf\n",
    "        self._latent_dim_mlp = latent_dim_mlp\n",
    "\n",
    "        # 建立MLP模型的user Embedding层和item Embedding层，输入的向量长度分别为用户的数量，item的数量，输出都是隐式空间的维度latent dim\n",
    "        self._embedding_user_mlp = torch.nn.Embedding(num_embeddings=self._num_users, embedding_dim=self._latent_dim_mlp)\n",
    "        self._embedding_item_mlp = torch.nn.Embedding(num_embeddings=self._num_users, embedding_dim=self._latent_dim_mlp)\n",
    "        \n",
    "        # 建立GMP模型的user Embedding层和item Embedding层，输入的向量长度分别为用户的数量，item的数量，输出都是隐式空间的维度latent dim\n",
    "        self._embedding_user_gmf = torch.nn.Embedding(num_embeddings=self._num_users, embedding_dim=self._latent_dim_gmf)\n",
    "        self._embedding_item_gmf = torch.nn.Embedding(num_embeddings=self._num_users, embedding_dim=self._latent_dim_gmf)\n",
    "\n",
    "        \n",
    "        # 全连接层\n",
    "        self._fc_layers = torch.nn.ModuleList()\n",
    "        for idx, (in_size, out_size) in enumerate(zip(config['layers'][:-1], config['layers'][1:])):\n",
    "            self._fc_layers.append(torch.nn.Linear(in_size, out_size))\n",
    "\n",
    "        # 激活函数\n",
    "        self._logistic = nn.Sigmoid()\n",
    "\n",
    "    @property\n",
    "    def fc_layers(self):\n",
    "        return self._fc_layers\n",
    "\n",
    "    @property\n",
    "    def embedding_user_gmf(self):\n",
    "        return self._embedding_user_gmf\n",
    "\n",
    "    @property\n",
    "    def embedding_item_gmf(self):\n",
    "        return self._embedding_item_gmf\n",
    "\n",
    "    @property\n",
    "    def embedding_user_mlp(self):\n",
    "        return self._embedding_user_mlp\n",
    "\n",
    "    @property\n",
    "    def embedding_item_mlp(self):\n",
    "        return self._embedding_item_mlp\n",
    "\n",
    "    def saveModel(self):\n",
    "        torch.save(self.state_dict(), self._config['model_name'])\n",
    "\n",
    "    @abstractmethod\n",
    "    def load_preTrained_weights(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "QfQf8EEfBIpU"
   },
   "outputs": [],
   "source": [
    "class NeuMF(NCF, nn.Module):\n",
    "    def __init__(self, config, latent_dim_gmf, latent_dim_mlp):\n",
    "        nn.Module.__init__(self)\n",
    "        NCF.__init__(self, config, latent_dim_gmf, latent_dim_mlp)\n",
    "\n",
    "        # 创建一个线性模型，输入为GMF模型和MLP模型的潜在特征向量长度之和，输出向量长度为1\n",
    "        self._affine_output = torch.nn.Linear(in_features=config['layers'][-1] + config['latent_dim_gmf'], out_features=1)\n",
    "\n",
    "    @property\n",
    "    def affine_output(self):\n",
    "        return self._affine_output\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding_mlp = self._embedding_user_mlp(user_indices)\n",
    "        item_embedding_mlp = self._embedding_item_mlp(item_indices)\n",
    "        user_embedding_gmf = self._embedding_user_gmf(user_indices)\n",
    "        item_embedding_gmf = self._embedding_item_gmf(item_indices)\n",
    "\n",
    "        # concat the two latent vector\n",
    "        mlp_vector = torch.cat([user_embedding_mlp, item_embedding_mlp], dim=-1)\n",
    "        # multiply the two latent vector\n",
    "        gmf_vector = torch.mul(user_embedding_gmf, item_embedding_gmf)\n",
    "\n",
    "        for idx, _ in enumerate(range(len(self._fc_layers))):\n",
    "            mlp_vector = self._fc_layers[idx](mlp_vector)\n",
    "            mlp_vector = torch.nn.ReLU()(mlp_vector)\n",
    "\n",
    "        vector = torch.cat([mlp_vector, gmf_vector], dim=-1)\n",
    "        logits = self._affine_output(vector)\n",
    "        rating = self._logistic(logits)\n",
    "        return rating\n",
    "\n",
    "    def load_preTrained_weights(self):\n",
    "        # 加载MLP模型参数\n",
    "        mlp_model = MLP(self._config['mlp_config'], self._config['mlp_config']['latent_dim_mlp'])\n",
    "        if self._config['use_cuda'] is True:\n",
    "            mlp_model.cuda()\n",
    "        state_dict = torch.load(self._config['pretrain_mlp'])\n",
    "                                # map_location=lambda storage, loc: storage.cuda(device=self._config['device_id']))\n",
    "                                # map_location = {'cuda:0': 'cpu'})\n",
    "        mlp_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        self._embedding_item_mlp.weight.data = mlp_model.embedding_item_mlp.weight.data\n",
    "        self._embedding_user_mlp.weight.data = mlp_model.embedding_user_mlp.weight.data\n",
    "        for idx in range(len(self._fc_layers)):\n",
    "            self._fc_layers[idx].weight.data = mlp_model.fc_layers[idx].weight.data\n",
    "\n",
    "        # 加载GMF模型参数\n",
    "        gmf_model = GMF(self._config['gmf_config'], self._config['gmf_config']['latent_dim_gmf'])\n",
    "        if self._config['use_cuda'] is True:\n",
    "            gmf_model.cuda()\n",
    "        state_dict = torch.load(self._config['pretrain_gmf'])\n",
    "                                # map_location=lambda storage, loc: storage.cuda(device=self._config['device_id']))\n",
    "                                # map_location = {'cuda:0': 'cpu'})\n",
    "        mlp_model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "        self._embedding_item_gmf.weight.data = gmf_model.embedding_item_gmf.weight.data\n",
    "        self._embedding_user_gmf.weight.data = gmf_model.embedding_user_gmf.weight.data\n",
    "\n",
    "        self._affine_output.weight.data = self._config['alpha'] * torch.cat([mlp_model.affine_output.weight.data, gmf_model.affine_output.weight.data], dim=-1)\n",
    "        self._affine_output.bias.data = self._config['alpha'] * (mlp_model.affine_output.bias.data + gmf_model.affine_output.bias.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cOn0JJRUEyTv"
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, config):\n",
    "        self._config = config\n",
    "        self._model = model\n",
    "        # 选择优化器\n",
    "        self._optimizer = pick_optimizer(self._model, self._config)\n",
    "        # 定义损失函数，对于隐反馈数据，这里使用交叉熵损失函数\n",
    "        self._crit = torch.nn.BCELoss()\n",
    "\n",
    "    def _train_single_batch(self, users, items, ratings):\n",
    "        \"\"\"\n",
    "        对单个小批量数据进行训练\n",
    "        :param users: user Tensor\n",
    "        :param items: item Tensor\n",
    "        :param ratings: rating Tensor\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if self._config['use_cuda'] is True:\n",
    "            # 将这些数据由CPU迁移到GPU\n",
    "            users, items, ratings = users.cuda(), items.cuda(), ratings.cuda()\n",
    "\n",
    "        # 先将梯度清零,如果不清零，那么这个梯度就和上一个mini-batch有关\n",
    "        self._optimizer.zero_grad()\n",
    "        \n",
    "        # 模型的输入users， items，调用forward进行前向传播\n",
    "        ratings_pred = self._model(users, items)\n",
    "        \n",
    "        # 通过交叉熵损失函数来计算损失, ratings_pred.view(-1)代表将预测结果摊平，变成一维的结构。\n",
    "        loss = self._crit(ratings_pred.view(-1), ratings)\n",
    "        \n",
    "        # 反向传播计算梯度\n",
    "        loss.backward()\n",
    "        # 梯度下降等优化器 更新参数\n",
    "        self._optimizer.step()\n",
    "        # 将loss的值提取成python的float类型\n",
    "        loss = loss.item()\n",
    "        return loss\n",
    "\n",
    "    def _train_an_epoch(self, train_loader, epoch_id):\n",
    "        \"\"\"\n",
    "        训练一个Epoch，即将训练集中的所有样本全部都过一遍\n",
    "        :param train_loader: Torch的DataLoader\n",
    "        :param epoch_id: 训练轮次Id\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # 告诉模型目前处于训练模式，启用dropout以及batch normalization\n",
    "        self._model.train()\n",
    "        total_loss = 0\n",
    "        best_loss = 100\n",
    "        # 从DataLoader中获取小批量的id以及数据\n",
    "        for batch_id, batch in enumerate(train_loader):\n",
    "            assert isinstance(batch[0], torch.LongTensor)\n",
    "            # 这里的user, item, rating大小变成了1024维了，因为batch_size是1024，即每次选取1024个样本数据进行训练\n",
    "            user, item, rating = batch[0], batch[1], batch[2]\n",
    "            rating = rating.float()\n",
    "            loss = self._train_single_batch(user, item, rating)\n",
    "#             print('[Training Epoch {}] Batch {}, Loss {}'.format(epoch_id, batch_id, loss))\n",
    "            \n",
    "            if loss < best_loss:\n",
    "                best_loss = loss\n",
    "                best_batch = batch_id\n",
    "                \n",
    "            total_loss += loss\n",
    "        print(\"the best # of batch: {}, at this term, loss = {} \\n\".format(best_batch, best_loss))\n",
    "        \n",
    "#         print('Training Epoch: {}, TotalLoss: {} \\n'.format(epoch_id, total_loss))\n",
    "\n",
    "    def train(self, sampleGenerator):\n",
    "        # 是否使用GPU加速\n",
    "        self.use_cuda()\n",
    "        # 是否使用预先训练好的参数\n",
    "        self.load_preTrained_weights()\n",
    "\n",
    "        for epoch in range(self._config['num_epoch']):\n",
    "            \n",
    "#             print('-' * 20 + ' Epoch {} starts '.format(epoch) + '-' * 20)\n",
    "\n",
    "            # 每个轮次都重新随机产生样本数据集\n",
    "            users, items, ratings = sampleGenerator(num_negatives=self._config['num_negative'])\n",
    "            # 构造一个DataLoader\n",
    "            data_loader = Construct_DataLoader(users=users, items=items, ratings=ratings,\n",
    "                                               batchsize=self._config['batch_size'])\n",
    "            # 训练一个轮次\n",
    "            self._train_an_epoch(data_loader, epoch_id=epoch)\n",
    "\n",
    "    def use_cuda(self):\n",
    "        if self._config['use_cuda'] is True:\n",
    "            assert torch.cuda.is_available(), 'CUDA is not available'\n",
    "            torch.cuda.set_device(self._config['device_id'])\n",
    "            self._model.cuda()\n",
    "\n",
    "    def load_preTrained_weights(self):\n",
    "        if self._config['pretrain'] is True:\n",
    "            self._model.load_preTrained_weights()\n",
    "\n",
    "    def save(self):\n",
    "        self._model.saveModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "--BkicAtIV69"
   },
   "outputs": [],
   "source": [
    "def pick_optimizer(network, params):\n",
    "    optimizer = None\n",
    "    print(\"at this term, we choose optimizer: \", params['optimizer'])\n",
    "    if params['optimizer'] == 'sgd':\n",
    "        optimizer = torch.optim.SGD(network.parameters(),\n",
    "                                    lr=params['sgd_lr'],\n",
    "                                    momentum=params['sgd_momentum'],\n",
    "                                    weight_decay=params['l2_regularization'])\n",
    "    if params['optimizer'] == 'asgd':\n",
    "        optimizer = torch.optim.ASGD(network.parameters(),\n",
    "                                    lr=params['asgd_lr'],\n",
    "                                    alpha=params['asgd_alpha'],\n",
    "                                    weight_decay=params['l2_regularization'])\n",
    "    elif params['optimizer'] == 'adam':\n",
    "        optimizer = torch.optim.Adam(network.parameters(),\n",
    "                                     lr=params['adam_lr'],\n",
    "                                     weight_decay=params['l2_regularization'])\n",
    "    elif params['optimizer'] == 'rmsprop':\n",
    "        optimizer = torch.optim.RMSprop(network.parameters(),\n",
    "                                        lr=params['rmsprop_lr'],\n",
    "                                        alpha=params['rmsprop_alpha'],\n",
    "                                        momentum=params['rmsprop_momentum'])\n",
    "    elif params['optimizer'] == 'adamax':\n",
    "        optimizer = torch.optim.Adamax(network.parameters(),\n",
    "                                        lr=params['adamax_lr'],\n",
    "                                        weight_decay=params['l2_regularization'])\n",
    "    elif params['optimizer'] == 'adadelta':\n",
    "        optimizer = torch.optim.Adadelta(network.parameters(),\n",
    "                                        lr=params['adadelta_lr'],\n",
    "                                        weight_decay=params['l2_regularization'])\n",
    "#     elif params['optimizer'] == 'nadam':\n",
    "#         optimizer = torch.optim.NAdam(network.parameters(),\n",
    "#                                         lr=params['nadam_lr'],\n",
    "#                                         weight_decay=params['l2_regularization'])\n",
    "\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "AiuCTVQOIqun"
   },
   "outputs": [],
   "source": [
    "class UserItemRatingDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Wrapper, convert input <user, item, rating> Tensor into torch Dataset\n",
    "    \"\"\"\n",
    "    def __init__(self, user_tensor, item_tensor, target_tensor):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            target_tensor: torch.Tensor, the corresponding rating for <user, item> pair\n",
    "        \"\"\"\n",
    "        self._user_tensor = user_tensor\n",
    "        self._item_tensor = item_tensor\n",
    "        self._target_tensor = target_tensor\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self._user_tensor[index], self._item_tensor[index], self._target_tensor[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._user_tensor.size(0)\n",
    "\n",
    "def Construct_DataLoader(users, items, ratings, batchsize):\n",
    "    assert batchsize > 0\n",
    "    dataset = UserItemRatingDataset(user_tensor=torch.LongTensor(users),\n",
    "                                    item_tensor=torch.LongTensor(items),\n",
    "                                    target_tensor=torch.LongTensor(ratings))\n",
    "    return DataLoader(dataset, batch_size=batchsize, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data and do training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RXYQpAGABXi-",
    "outputId": "2a054f0c-ab27-4f10-8768-f0df7ef1cf50"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at this term, we choose optimizer:  rmsprop\n",
      "the best # of batch: 31310, at this term, loss = 0.19889022409915924 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:65: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0632]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.6163]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.1850]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.0044]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.1332]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.2482]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.8868]], grad_fn=<SigmoidBackward>)\n",
      "tensor([[0.8839]], grad_fn=<SigmoidBackward>)\n",
      "the using time at this is  210.84840273857117  seconds \n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "gmf_config = {'num_epoch': 1,\n",
    "              'batch_size': 1024,\n",
    "              \n",
    "              # 'optimizer': 'sgd',\n",
    "              # 'sgd_lr': 1e-3,\n",
    "              # 'sgd_momentum': 0.9,\n",
    "              \n",
    "              # 'optimizer': 'asgd',\n",
    "              # 'asgd_lr': 1e-3,\n",
    "              # 'asgd_alpha': 0.99,\n",
    "              \n",
    "              'optimizer': 'rmsprop',\n",
    "              'rmsprop_lr': 1e-3,\n",
    "              'rmsprop_alpha': 0.99,\n",
    "              'rmsprop_momentum': 0,\n",
    "              \n",
    "              # 'optimizer': 'adamax',\n",
    "              # 'adamax_lr': 1e-3,\n",
    "              \n",
    "              # 'optimizer': 'adamdelta',\n",
    "              # 'adamdelta_lr': 1e-3,\n",
    "              \n",
    "#               'optimizer': 'nadam',\n",
    "#               'nadam_lr': 1e-3,\n",
    "              \n",
    "              # 'optimizer': 'adam',\n",
    "              # 'adam_lr': 1e-3,\n",
    "              'l2_regularization': 0, # 0.01\n",
    "              \n",
    "              'num_users': 6040,\n",
    "              'num_items': 3706,\n",
    "              'latent_dim_gmf': 8,\n",
    "              'num_negative': 4,\n",
    "              'layers': [],\n",
    "              'pretrain': False, # do not modify this\n",
    "              'use_cuda': False,\n",
    "              'device_id': 2,\n",
    "              'model_name': './NCF_GMF.model'\n",
    "              }\n",
    "\n",
    "mlp_config = {'num_epoch': 1,\n",
    "              'batch_size': 256,  # 1024,\n",
    "              \n",
    "              # 'optimizer': 'sgd',\n",
    "              # 'sgd_lr': 1e-3,\n",
    "              # 'sgd_momentum': 0.9,\n",
    "\n",
    "              # 'optimizer': 'asgd',\n",
    "              # 'asgd_lr': 1e-3,\n",
    "              # 'asgd_alpha': 0.99,              \n",
    "              \n",
    "              'optimizer': 'rmsprop',\n",
    "              'rmsprop_lr': 1e-3,\n",
    "              'rmsprop_alpha': 0.99,\n",
    "              'rmsprop_momentum': 0,\n",
    "              \n",
    "              # 'optimizer': 'adamax',\n",
    "              # 'adamax_lr': 1e-3,\n",
    "              \n",
    "              # 'optimizer': 'adadelta',\n",
    "              # 'adamdelta_lr': 1e-3,\n",
    "              \n",
    "#               'optimizer': 'nadam',\n",
    "#               'nadam_lr': 1e-3,\n",
    "              \n",
    "              # 'optimizer': 'adam',\n",
    "              # 'adam_lr': 1e-3,\n",
    "              'l2_regularization': 0.0000001,  # MLP model is sensitive to hyper params\n",
    "              \n",
    "              'num_users': 6040,\n",
    "              'num_items': 3706,\n",
    "              'latent_dim_mlp': 8,\n",
    "              'latent_dim_gmf': 8,\n",
    "              'num_negative': 4,\n",
    "              'layers': [16,64,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "              'use_cuda': False,\n",
    "              'device_id': 2,\n",
    "              'pretrain': True,\n",
    "              'gmf_config': gmf_config,\n",
    "              'pretrain_gmf': './NCF_GMF.model',\n",
    "              'model_name': './NCF_MLP.model'\n",
    "              }\n",
    "\n",
    "neumf_config = {'num_epoch': 1,\n",
    "                'batch_size': 128, #1024\n",
    "                \n",
    "                # 'optimizer': 'sgd',\n",
    "                # 'sgd_lr': 1e-3,\n",
    "                # 'sgd_momentum': 0.9,\n",
    "              \n",
    "              # 'optimizer': 'asgd',\n",
    "              # 'asgd_lr': 1e-3,\n",
    "              # 'asgd_alpha': 0.99,                \n",
    "                \n",
    "               'optimizer': 'rmsprop',\n",
    "               'rmsprop_lr': 1e-3,\n",
    "               'rmsprop_alpha': 0.99,\n",
    "               'rmsprop_momentum': 0,\n",
    "               \n",
    "               # 'optimizer': 'adamax',\n",
    "               # 'adamax_lr': 1e-3,\n",
    "              \n",
    "               # 'optimizer': 'adadelta',\n",
    "               # 'adadelta_lr': 1e-3,\n",
    "                \n",
    "#                'optimizer': 'nadam',\n",
    "#                'nadam_lr': 1e-3,\n",
    "                \n",
    "                # 'optimizer': 'adam',\n",
    "                # 'adam_lr': 1e-3,\n",
    "                'l2_regularization': 0.01,\n",
    "                \n",
    "                'num_users': 6040,\n",
    "                'num_items': 3706,\n",
    "                'latent_dim_gmf': 8,\n",
    "                'latent_dim_mlp': 8,\n",
    "                'num_negative': 4,\n",
    "                'layers': [16,32,16,8],  # layers[0] is the concat of latent user vector & latent item vector\n",
    "                'alpha': 0.5, # 用于控制GMF和MLP模型参数的权重\n",
    "                'use_cuda': False,\n",
    "                'device_id': 2,\n",
    "                'pretrain': False, # if you set this to True, you must guarantee the  Neumf layers is the same as the mlp layers\n",
    "                'gmf_config': gmf_config,\n",
    "                'pretrain_gmf': './NCF_GMF.model',\n",
    "                'mlp_config': mlp_config,\n",
    "                'pretrain_mlp': './NCF_MLP.model',\n",
    "                'model_name': './NCF_NeuMF.model'\n",
    "                }\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    ####################################################################################\n",
    "    # NCF 神经协同过滤算法\n",
    "    ####################################################################################\n",
    "    begin_time = time.time()   \n",
    "    \n",
    "    dp = DataProcess(\"./ratings.dat\")\n",
    "    \n",
    "    \n",
    "    # 初始化GMP模型\n",
    "    # config = gmf_config\n",
    "    # model = GMF(config, config['latent_dim_gmf'])\n",
    "\n",
    "    # # 初始化MLP模型\n",
    "    # config = mlp_config\n",
    "    # model = MLP(config, config['latent_dim_mlp'])\n",
    "\n",
    "    # 初始化NeuMF模型\n",
    "    config = neumf_config\n",
    "    model = NeuMF(config, config['latent_dim_gmf'], config['latent_dim_mlp'])\n",
    "\n",
    "    # ###############################################################\n",
    "    # 模型训练阶段\n",
    "    # ###############################################################\n",
    "    trainer = Trainer(model=model, config=config)\n",
    "    trainer.train(dp.sample_generator)\n",
    "    trainer.save()\n",
    "\n",
    "    # ###############################################################\n",
    "    # 模型测试阶段\n",
    "    # ###############################################################\n",
    "\n",
    "    # 加载数据集\n",
    "    dp = DataProcess(\"./ratings.dat\")\n",
    "\n",
    "    config = neumf_config\n",
    "    neumf = NeuMF(config, config['latent_dim_gmf'], config['latent_dim_mlp'])\n",
    "    state_dict = torch.load(\"./NCF_NeuMF.model\", map_location=torch.device('cpu'))\n",
    "    neumf.load_state_dict(state_dict, strict=False)\n",
    "    \n",
    "\n",
    "#     print(neumf.forward(torch.LongTensor([1]), torch.LongTensor([1193])))\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([661])))\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([914])))\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([3408])))\n",
    "\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([1245])))\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([32])))\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([4])))\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.LongTensor([62])))\n",
    "\n",
    "    print(neumf.forward(torch.IntTensor([1]), torch.IntTensor([1193])))\n",
    "    print(neumf.forward(torch.IntTensor([1]),torch.IntTensor([661])))\n",
    "    print(neumf.forward(torch.IntTensor([1]),torch.IntTensor([914])))\n",
    "    print(neumf.forward(torch.IntTensor([1]),torch.IntTensor([3408])))\n",
    "\n",
    "    print(neumf.forward(torch.IntTensor([1]),torch.IntTensor([1245])))\n",
    "    print(neumf.forward(torch.IntTensor([1]),torch.IntTensor([32])))\n",
    "    print(neumf.forward(torch.IntTensor([1]),torch.IntTensor([4])))\n",
    "    print(neumf.forward(torch.IntTensor([1]),torch.IntTensor([62])))\n",
    "    \n",
    "#     print(neumf.forward(torch.LongTensor([1]), torch.IntTensor([1193])))\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.IntTensor([661])))\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.IntTensor([914])))\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.IntTensor([3408])))\n",
    "\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.IntTensor([1245])))\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.IntTensor([32])))\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.IntTensor([4])))\n",
    "#     print(neumf.forward(torch.LongTensor([1]),torch.IntTensor([62])))\n",
    "    \n",
    "    use_time = time.time() - begin_time\n",
    "    print(\"the using time at this is \", use_time, \" seconds \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## partial results record\n",
    "\n",
    "Partial resutls are recorded and ploted scatter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the time record (part) for different optimizer when use LongTensor\n",
    "long_time_adam = [676.56, 536.05, 612.68, 678.25, 549.54] \n",
    "long_time_adamax = [496.13, 503.63, 486.02, 603.81, 496.56] \n",
    "long_time_adadelta = [239.85, 254.93, 247.23, 240.73, 246.92]\n",
    "long_time_sgd = [193.94, 198.92, 193.30, 193.42, 194.15]\n",
    "long_time_asgd = [193.72, 195.04, 195.85, 195.88, 197.92]\n",
    "long_time_rmsprop = [216.45, 216.86, 218.18, 217.92, 239.32]\n",
    "\n",
    "long_time = long_time_adam\n",
    "long_time.extend(long_time_adamax)\n",
    "long_time.extend(long_time_adadelta)\n",
    "long_time.extend(long_time_sgd)\n",
    "long_time.extend(long_time_asgd)\n",
    "long_time.extend(long_time_rmsprop)\n",
    "avg_long_time = sum(long_time) / len(long_time)\n",
    "# print(\"the average of time using LongTensor: \", avg_long_time)\n",
    "\n",
    "# the time record (part) for different optimizer when use intTensor\n",
    "int_time_adam = [654.27, 663.70, 559.99, 671.35, 671.74]\n",
    "int_time_adamax = [495.63, 498.69,  519.06, 524.37, 532.33]\n",
    "int_time_adadelta = [234.17, 233.86, 232.57, 237.85, 240.46]\n",
    "int_time_sgd = [210.57, 195.53,  203.42, 217.87, 208.70]\n",
    "int_time_asgd = [210.31, 201.37, 195.31, 195.78, 193.26]\n",
    "int_time_rmsprop = [228.25, 224.06, 242.05, 233.82, 236.08]\n",
    "\n",
    "int_time = int_time_adam\n",
    "int_time.extend(int_time_adamax)\n",
    "int_time.extend(int_time_adadelta)\n",
    "int_time.extend(int_time_sgd)\n",
    "int_time.extend(int_time_asgd)\n",
    "int_time.extend(int_time_rmsprop)\n",
    "avg_int_time = sum(int_time) / len(int_time)\n",
    "# print(\"the average of time using intTensor: \", avg_int_time)\n",
    "\n",
    "# the best loss record (part) for different optimizer\n",
    "adam_loss = [0.3187, 0.3159, 0.2994, 0.3275, 0.3252, 0.3111, 0.3383, 0.3361, 0.3198, 0.3147]\n",
    "adam_time = [676.56, 536.05, 612.68, 678.25, 549.54, 654.27, 663.70, 559.99, 671.35, 671.74]\n",
    "\n",
    "adamax_loss = [0.3083, 0.3165, 0.3141, 0.3176, 0.3292, 0.3281, 0.3278, 0.3276, 0.3157, 0.3289]\n",
    "adamax_time = [496.13, 503.63, 486.02, 603.81, 496.56, 495.63, 498.69,  519.06, 524.37, 532.33]\n",
    "\n",
    "adadelta_loss = [0.3519, 0.3274, 0.4586, 0.4098, 0.3550, 0.3532, 0.3447, 0.3303, 0.3527, 0.3850]\n",
    "adadelta_time = [234.17, 233.86, 232.57, 237.85, 240.46, 239.85, 254.93, 247.23, 240.73, 246.92]\n",
    "\n",
    "sgd_loss = [0.3286, 0.3199, 0.3282, 0.3313, 0.3296, 0.3280, 0.3093, 0.3378, 0.3402, 0.3203]\n",
    "sgd_time = [193.94, 198.92, 193.30, 193.42, 194.15, 210.57, 195.53,  203.42, 217.87, 208.70]\n",
    "\n",
    "asgd_loss = [0.3170, 0.3358, 0.3385, 0.3410, 0.3284, 0.3379, 0.3407, 0.3384, 0.3136, 0.3181]\n",
    "asgd_time = [210.31, 201.37, 195.31, 195.78, 193.26, 193.72, 195.04, 195.85, 195.88, 197.92]\n",
    "\n",
    "rmsprop_loss = [0.1921, 0.1939, 0.1723, 0.1881, 0.1998, 0.2009, 0.1956, 0.1955, 0.2033,  0.1903]\n",
    "rmsprop_time = [216.45, 216.86, 218.18, 217.92, 239.32, 228.25, 224.06, 242.05, 233.82, 236.08]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize = (7,5))\n",
    "plt.scatter(adam_time, adam_loss, marker = 'o')\n",
    "plt.scatter(adamax_time, adamax_loss, marker = 'x')\n",
    "plt.scatter(adadelta_time, adadelta_loss, marker = '+')\n",
    "plt.scatter(sgd_time, sgd_loss, marker = 'd')\n",
    "plt.scatter(asgd_time, asgd_loss, marker = '*')\n",
    "plt.scatter(rmsprop_time, rmsprop_loss, marker = '^')\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend([\"adam\", \"adamax\", \"adadelta\", \"sgd\", \"asgd\", \"rmsprop\"])\n",
    "plt.show()\n",
    "\n",
    "# plt.savefig('optim_performance.jpg', dpi=300) #指定分辨率保存"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "BookRecom.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
